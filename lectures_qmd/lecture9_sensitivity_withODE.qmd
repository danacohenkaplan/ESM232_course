---
title: "Sensitivity with ODEs"
format: revealjs
theme: solarized
resources: ["img/"]
css: ["slides.css"]
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(deSolve)
library(here)
library(sensitivity)
```

## Dynamic models {.scrollable}

-   models that have feedbacks (conditions evolve through time)

-   numerical integration - usually done with a solver

    -   only one independent variable ordinary differential equation (e.g just time)
    -   we can use the ODE solver
    -   derivative is first order
    -   (e.g $dy/dt$ = ; not $d^2y/dt$+dy/dy = f(y,t))
    -   there also solvers for high order and partial differential equations

## Sensitivity Analysis of a Differential Equation {.scrollable}

We can apply sensitivity analysis to a differential equation

A key issue where is sensitivity of what?

Dynamic models often give you many many outputs

-   time series (streamflow every day for a year, population for 30 years)
-   or output over space (spatially averaged concentration after 10 days?)

So if we are asking 'sensitivity of what' we need to summarize results in some way (reduce their dimensionality )

Ideas?

## Some options for reducing output dimensionality (summarizing output) {.scrollable}

Depends on what is important for your model application

-   max
-   mean
-   min
-   total
-   variation
-   time it takes for something to happen

So a key step in sensitivity analysis with a dynamics model is summarizing results into a few key measures

Its useful to turn that summarizing workflow into a function

## In class exerise {.scrollable}

For the diffusion model that we've been working with

-   write a function that takes as input the output of diffusion function and returns a summary
    -   the summary should be a single value
        -   (or if you are ambitious a list of several single value summary statistics)
    -   you can be creative here - what would be an interesting summary
    -   include in comments at the top of the function a rationale for your summary choice
-   check that it works by applying it to

Upload your function to Canvas - InClass in this weeks Canvas - we will give 10pts for all loaded functions

## Workflow for Sensitivity Analysis {.scrollable}

-   implement (or identify pre-existing) dynamic model

-   obtain parameter sets (from sobel or LHS)

-   build a function that will extract the information (metrics) you want from your dynamic model (output of the ode)

-   create a data structure to store the metrics for each parameter set - in my example I call it metrics (but could be anything)

-   decide on initial conditions and time period over which you will run the model

-   run ODE for each parameter sets to fill in this metrics data structure

    -   its usually helpful to create a wrapper function 
        - runs ODE 
        - extracts metrics
    -   run wrapper function for each parameter sets

-   send the metrics data structure back to the sensitivity analysis object (from sobel or LHS)

-   plot and analyze results

## Example with our population ODE {.scrollable}

Lets first generate parameter sets and figure out how to run  across uncertainty in just one those parameter sets

Always a good practice to "try" you model on one parameter set *before* trying to run for all parameters

```{r sen}
source(here("R/dpopgrowth.R"))

dpopgrowth

# lets start with sobel
library(sensitivity)

# come up with first set of sample parameters
# we will assume that we know the initial population,

Pinitial <- 10

# want to learn about sensitivity to growth rate (r) and carrying capacity
# set the number of parameters
np <- 2000
K <- rnorm(mean = 200, sd = 50, n = np)
r <- rnorm(mean = 0.05, sd = 0.01, n = np)
X1 <- cbind.data.frame(r = r, K = K)

# repeat to get our second set of samples
K <- rnorm(mean = 200, sd = 50, n = np)
r <- rnorm(mean = 0.05, sd = 0.01, n = np)
X2 <- cbind.data.frame(r = r, K = K)

# fix any negative values and they are not meaningful
X1 <- X1 %>% map_df(pmax, 0.0)
X2 <- X2 %>% map_df(pmax, 0.0)

# create our sobel object and get sets ofparameters for running the model

sens_P <- sobolSalt(model = NULL, X1, X2, nboot = 300)

# our parameter sets are
head(sens_P$X)

# lets add names
colnames(sens_P$X) <- c("r", "K")

head(sens_P$X)
```

## Running the ODE and summarizing output {.scrollable}

-   run our differential equation and keep the output

BUT what output do we want to keep?

A couple of options

-   how about maximum population if we run the model for 200 years,
-   how many years to get to the carrying capacity
-   how many year to get to some pre-determined threshold

For illustration lets look at running just one parameter sets and summarizing results

```{r runone}
sens_P$X[1, ]
# recall ODE needs ALL of our parameters in a single list
# initial population and times for which we want output
Pinitial

# gets results for 200 years (evaluating every year)
simtimes <- seq(from = 1, to = 200)
parms <- list(r = sens_P$X[1, "r"], K = sens_P$X[1, "K"])

# or
parms <- list(r = as.data.frame(sens_P$X)$r[1], K = as.data.frame(sens_P$X)$K[1])

result <- ode(y = Pinitial, times = simtimes, func = dpopgrowth, parms = parms)

head(result)
colnames(result) <- c("time", "P")
# turn it into a data frame
result <- as.data.frame(result)
ggplot(result, aes(time, P)) +
  geom_point()

# extract our metrics of interest  from this
# maximum population it gets to
maxpop <- max(result$P)
maxpop

# years required to get to a threshold population (150)
# which will tell when this occurs - we will take the first one
thresh <- 150
idx <- which(result$P > thresh)[1]

# if it never gets there
idx <- ifelse(is.na(idx), length(result$P), idx)
# turn this index into a year (might be the same if time step in 1 but just in case it isn't)
threshyear <- result$time[idx]
threshyear


ggplot(result, aes(time, P)) +
  geom_line() +
  geom_vline(xintercept = threshyear, col = "red") +
  labs(y = "Population", title = "When do we get to 150")

# or how about threshold of 50% of carrying capacity
thresh <- 0.5 * sens_P$X[1, "K"]
idx <- which(result$P > thresh)[1]

# if it never gets there
idx <- ifelse(is.na(idx), length(result$P), idx)
# turn this index into a year (might be the same if time step in 1 but just in case it isn't)
threshyear <- result$time[idx]
threshyear


ggplot(result, aes(time, P)) +
  geom_line() +
  geom_vline(xintercept = threshyear, col = "red") +
  labs(y = "Population", title = "When do we get to 50%\nof carrying capacity")
```

## Make a different metric or ODE {.scrollable}

-   try a metric that gives you the population at year 5

-   change the way carrying capacity is used

## Try it running ODE for *all* parameters {.scrollable}

One issue is the volume of output! you have a time series for *each* parameter set

So just save metrics

Lets create two additional functions that will help us

-   a function that computes the metrics we want

-   a function that runs our ode solver and computes the metrics (I call it a **wrapper** function as it is really just a workflow/wrapper to call ode solver and then compute metrics)

-   wrapper takes as input

    -   parameters
    -   initial conditions
    -   simulation time
    -   ode (function name)
    -   how to compute metrics (function name)

-   always test to make sure it works (good coding practice)

```{r sen2}
# turn computing our metrics into a function

compute_metrics <- function(result, thresh) {
  maxpop <- max(result$P)
  idx <- which(result$P > thresh)[1]
  idx <- ifelse(is.na(idx), length(result$P), idx)
  threshyear <- result$time[idx]
  return(list(maxpop = maxpop, threshyear = threshyear))
}

# try it on our first parameter set, and look at when it gets to 100
compute_metrics(result, 100)

# great but we need to apply the ode and this function for all of our parameters



# define a wrapper function to do everything we need - run solver and compute metrics - and send back results for each parameter

# lets make the threshold 90% of carrying capacity

p_wrapper <- function(r, K, Pinitial, simtimes, odefunc, metricfunc) {
  parms <- list(r = r, K = K)
  result <- ode(y = Pinitial, times = simtimes, func = odefunc, parms = parms, method="euler")
  colnames(result) <- c("time", "P")
  # get metrics
  metrics <- metricfunc(as.data.frame(result), thresh = 100)
  return(metrics)
}

# test
p_wrapper(
  r = 0.01, K = 150, Pinitial = 3, simtimes = seq(from = 1, to = 10),
  odefunc = dpopgrowth, metricfunc = compute_metrics
)
```

## Next step {.scrollable}

Run the wrapper for all parameters and look at results

```{r userwarpper, error=TRUE}
# now use pmap as we did before

allresults <- as.data.frame(sens_P$X) %>% pmap(p_wrapper, Pinitial = Pinitial, simtimes = simtimes, odefunc = dpopgrowth, metricfunc = compute_metrics)

# extract out results from pmap into a data frame
allres <- allresults %>% map_dfr(`[`, c("maxpop", "threshyear"))


# create boxplots
tmp <- allres %>% pivot_longer(cols = everything(), names_to = "metric", values_to = "value")
ggplot(tmp, aes(metric, value, col = metric)) +
  geom_boxplot()
```

## Compute the sobol indicies for each metric {.scrollable}

-   save the *tell* to different objects so you can keep re-using the original sobel object

-   look at total effect and first order sensitivity

```{r sen3}
# sobol can only handle one output at a time  - so we will need to do them separately

sens_P_maxpop <- sensitivity::tell(sens_P, allres$maxpop)

# first-order indices (main effect without co-variance)
rownames(sens_P_maxpop$S) <- c("r", "K")
sens_P_maxpop$S

# total sensitivity index -note that this partitions the output variance
rownames(sens_P_maxpop$T) <- c("r", "K")
sens_P_maxpop$T




# create another one for max year
sens_P_threshyear <- sensitivity::tell(sens_P, allres$threshyear)
# first-order indices (main effect without co-variance)
rownames(sens_P_threshyear$S) <- c("r", "K")
sens_P_threshyear$S

# total sensitivity index -note that this partitions the output variance - so values sum to 1
rownames(sens_P_threshyear$T) <- c("r", "K")
sens_P_threshyear$T
```

## Negative sobol first order indices {.scrollable}

if confidence interval includes zero - not a problem

if it doesn't there are numerical issues - try running more samples

## Error messages from ODE {.scrollable}

*In lsoda(y, times, func, parms, ...) : an excessive amount of work (\> maxsteps ) was done, but integration was not successful - increase maxsteps*

Suggest that the solver (numerical integration) had issues

-   increasing maxsteps can help

    ```         
    *result = ode(y=Pinitial, times=simtimes, func=func, parms=parms, maxsteps=100000) *
    ```

-   trying different methods

    ```         
    *result = ode(y=Pinitial, times=simtimes, func=func, parms=parms, method="daspk")*
    ```

-   "stiff" problems are harder for numerical integration to solve - (small changes have big impacts); a threshold carrying capacity does that

## [Assignment]{style="color:orange"} {.scrollable}

# The model

Consider the following model of forest growth (where forest size in measured in units of carbon (C))

-   $dC/dt  = r*C$ for forests where C is below a threshold canopy closure

-   $dC/dt = g*(1- C/K)$ for forests where carbon is at or above the threshold canopy closure

-   and $K$ is a carrying capacity in units of carbon

The size of the forest ($C$), Canopy closure threshold and carrying capacity are all in units of carbon

You could think of the canopy closure threshold as the size of the forest at which growth rates change from exponential to linear You can think of $r$, as early exponential growth rate and $g$ as the linear growth rate once canopy closure has been reached

## [Your task]{style="color:orange"} {.scrollable}

1.  Implement this model in R (as a differential equation)

2.  Run the model for 300 years (using the ODE solver) starting with an initial forest size of 10 kg/C, and using the following parameters:

-   canopy closure threshold of 50 kgC
-   $K$ = 250 kg C (carrying capacity)
-   $r$= 0.01 (exponential growth rate before before canopy closure)
-   $g$ = 2 kg/year (linear growth rate after canopy closure)

3.  Graph the results. Here you are graphing the trajectory with the parameters as given (e.g no uncertainty)

4.  Run a sobol global (vary all parameters at the same time) sensitivity analysis that explores how the estimated **maximum forest size** (e.g maximum of $C$ 300 years, varies with these parameters

-   pre canopy closure growth rate ($r$)
-   post-canopy closure growth rate ($g$)
-   canopy closure threshold and carrying capacity($K$)

Assume that parameters are all normally distributed with means as given above and standard deviation of 10% of mean value

5.  Graph the results of the sensitivity analysis as a box plot of maximum forest size and record the two Sobol indices (**S** and **T**).

6.  In 2-3 sentences, discuss what the results of your simulation might mean. (For example think about how what parameters climate change might influence).

Submit R markdown with model implementation, graphs and sensitivity analysis and R file with your model

You can work in groups or individually

## Extra Credit

Compute Sobol indices for a second metric: forest size after a 100 years

OR

Try using Sobol for the diffusion model - what would be your metric?
